
@inproceedings{austin2021structured,
    author = {Jacob Austin and
Daniel D. Johnson and
Jonathan Ho and
Daniel Tarlow and
Rianne van den Berg},
    booktitle = {Advances in Neural Information Processing Systems 34: Annual Conference
on Neural Information Processing Systems 2021, NeurIPS 2021, December
6-14, 2021, virtual},
    editor = {Marc'Aurelio Ranzato and
Alina Beygelzimer and
Yann N. Dauphin and
Percy Liang and
Jennifer Wortman Vaughan},
    pages = {17981--17993},
    timestamp = {Tue, 03 May 2022 01:00:00 +0200},
    title = {Structured Denoising Diffusion Models in Discrete State-Spaces},
    year = {2021}
}

@article{campbell2022continuous,
  title={A continuous time framework for discrete denoising models},
  author={Campbell, Andrew and Benton, Joe and De Bortoli, Valentin and Rainforth, Thomas and Deligiannidis, George and Doucet, Arnaud},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={28266--28279},
  year={2022}
}

@article{ye2024beyond,
  title={Beyond Autoregression: Discrete Diffusion for Complex Reasoning and Planning},
  author={Ye, Jiacheng and Gao, Jiahui and Gong, Shansan and Zheng, Lin and Jiang, Xin and Li, Zhenguo and Kong, Lingpeng},
  journal={The Thirteenth International Conference on Learning Representations},
  year={2025}
}
@article{dziri2024faith,
  title={Faith and fate: Limits of transformers on compositionality},
  author={Dziri, Nouha and Lu, Ximing and Sclar, Melanie and Li, Xiang Lorraine and Jiang, Liwei and Lin, Bill Yuchen and Welleck, Sean and West, Peter and Bhagavatula, Chandra and Le Bras, Ronan and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{bubeck2023sparks,
  title={Sparks of artificial general intelligence: Early experiments with gpt-4},
  author={Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
  journal={arXiv preprint arXiv:2303.12712},
  year={2023}
}
@article{bachmann2024pitfalls,
  title={The pitfalls of next-token prediction},
  author={Bachmann, Gregor and Nagarajan, Vaishnavh},
  journal={Proceedings of the 41st International Conference on Machine Learning},
  year={2024}
}

@inproceedings{hoogeboom2021argmax,
    author = {Emiel Hoogeboom and
Didrik Nielsen and
Priyank Jaini and
Patrick Forr{\'{e}} and
Max Welling},
    booktitle = {Advances in Neural Information Processing Systems 34: Annual Conference
on Neural Information Processing Systems 2021, NeurIPS 2021, December
6-14, 2021, virtual},
    editor = {Marc'Aurelio Ranzato and
Alina Beygelzimer and
Yann N. Dauphin and
Percy Liang and
Jennifer Wortman Vaughan},
    pages = {12454--12465},
    timestamp = {Tue, 03 May 2022 01:00:00 +0200},
    title = {Argmax Flows and Multinomial Diffusion: Learning Categorical Distributions},
    year = {2021}
}
@inproceedings{song2023consistency,
  title={Consistency Models},
  author={Song, Yang and Dhariwal, Prafulla and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={32211--32252},
  year={2023},
  organization={PMLR}
}
@article{nie2025large,
  title={Large Language Diffusion Models},
  author={Nie, Shen and Zhu, Fengqi and You, Zebin and Zhang, Xiaolu and Ou, Jingyang and Hu, Jun and Zhou, Jun and Lin, Yankai and Wen, Ji-Rong and Li, Chongxuan},
  journal={arXiv preprint arXiv:2502.09992},
  year={2025}
}
@article{gong2024scaling,
  title={Scaling Diffusion Language Models via Adaptation from Autoregressive Models},
  author={Gong, Shansan and Agarwal, Shivam and Zhang, Yizhe and Ye, Jiacheng and Zheng, Lin and Li, Mukai and An, Chenxin and Zhao, Peilin and Bi, Wei and Han, Jiawei and others},
  journal={The Thirteenth International Conference on Learning Representations},
  year={2025}
}
@article{Zheng2023ARD,
    author = {Lin Zheng and Jianbo Yuan and Lei Yu and Lingpeng Kong},
    journal = {First Conference on Language Modeling},
    title = {A Reparameterized Discrete Diffusion Model for Text Generation},
    year = {2023}
}
@article{yang2024qwen2,
  title={Qwen2. 5 technical report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}
@article{grattafiori2024llama,
  title={The llama 3 herd of models},
  author={Grattafiori, Aaron and Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Vaughan, Alex and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}
@inproceedings{ye2025implicit,
  title={Implicit Search via Discrete Diffusion: A Study on Chess},
  author={Ye, Jiacheng and Wu, Zhenyu and Gao, Jiahui and Wu, Zhiyong and Jiang, Xin and Li, Zhenguo and Kong, Lingpeng},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year = {2025}
}
@inproceedings{ye2025dot,
  title={Diffusion of Thought: Chain-of-Thought Reasoning in Diffusion Language Models},
  author={Ye, Jiacheng and Gong, Shansan and Chen, Liheng and Zheng, Lin and Gao, Jiahui and Shi, Han and Wu, Chuan and Jiang, Xin and Li, Zhenguo and Bi, Wei and others},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year = {2025}
}
@article{lambert2024t,
  title={T$\backslash$" ulu 3: Pushing frontiers in open language model post-training},
  author={Lambert, Nathan and Morrison, Jacob and Pyatkin, Valentina and Huang, Shengyi and Ivison, Hamish and Brahman, Faeze and Miranda, Lester James V and Liu, Alisa and Dziri, Nouha and Lyu, Shane and others},
  journal={arXiv preprint arXiv:2411.15124},
  year={2024}
}
@misc{allal2025smollm2smolgoesbig,
      title={SmolLM2: When Smol Goes Big -- Data-Centric Training of a Small Language Model}, 
      author={Loubna Ben Allal and Anton Lozhkov and Elie Bakouch and Gabriel Martín Blázquez and Guilherme Penedo and Lewis Tunstall and Andrés Marafioti and Hynek Kydlíček and Agustín Piqueres Lajarín and Vaibhav Srivastav and Joshua Lochner and Caleb Fahlgren and Xuan-Son Nguyen and Clémentine Fourrier and Ben Burtenshaw and Hugo Larcher and Haojun Zhao and Cyril Zakka and Mathieu Morlon and Colin Raffel and Leandro von Werra and Thomas Wolf},
      year={2025},
      eprint={2502.02737},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.02737}, 
}
@article{zheng2024natural,
  title={Natural plan: Benchmarking llms on natural language planning},
  author={Zheng, Huaixiu Steven and Mishra, Swaroop and Zhang, Hugh and Chen, Xinyun and Chen, Minmin and Nova, Azade and Hou, Le and Cheng, Heng-Tze and Le, Quoc V and Chi, Ed H and others},
  journal={arXiv preprint arXiv:2406.04520},
  year={2024}
}
@article{snell2024scaling,
  title={Scaling llm test-time compute optimally can be more effective than scaling model parameters},
  author={Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral},
  journal={arXiv preprint arXiv:2408.03314},
  year={2024}
}
@article{muennighoff2025s1,
  title={s1: Simple test-time scaling},
  author={Muennighoff, Niklas and Yang, Zitong and Shi, Weijia and Li, Xiang Lisa and Fei-Fei, Li and Hajishirzi, Hannaneh and Zettlemoyer, Luke and Liang, Percy and Cand{\`e}s, Emmanuel and Hashimoto, Tatsunori},
  journal={arXiv preprint arXiv:2501.19393},
  year={2025}
}
@article{geiping2025scaling,
  title={Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach},
  author={Geiping, Jonas and McLeish, Sean and Jain, Neel and Kirchenbauer, John and Singh, Siddharth and Bartoldson, Brian R and Kailkhura, Bhavya and Bhatele, Abhinav and Goldstein, Tom},
  journal={arXiv preprint arXiv:2502.05171},
  year={2025}
}