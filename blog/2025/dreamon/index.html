<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-Size Canvas | HKU NLP Group </title> <meta name="author" content="HKU NLP Group "> <meta name="description" content="A simple yet effective approach to unlock variable-length generation for diffusion language models."> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon.png"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://hkunlp.github.io/blog/2025/dreamon/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{inlineMath:[["$","$"]],tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-Size Canvas",
      "description": "A simple yet effective approach to unlock variable-length generation for diffusion language models.",
      "published": "July 15, 2025",
      "authors": [
        {
          "author": "Zirui Wu",
          "authorURL": "https://williamzr.github.io/",
          "affiliations": [
            {
              "name": "University of Hong Kong",
              "url": ""
            }
          ]
        }
        
      ]
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">HKU NLP Group¬†</span></a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">People</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/seminar/">HKUNLP Seminar</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-Size Canvas</h1> <p>A simple yet effective approach to unlock variable-length generation for diffusion language models.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#effective-variable-length-generation-on-infilling">Effective Variable-length Generation on Infilling</a></div> <div><a href="#dreamon-masked-diffusion-with-augmented-states">DreamOn: Masked Diffusion with Augmented States</a></div> <div><a href="#implementation">Implementation</a></div> <div><a href="#evaluation">Evaluation</a></div> <div><a href="#analysis">Analysis</a></div> <div><a href="#conclusion">Conclusion</a></div> </nav> </d-contents> <div style="display:none"> $$ \definecolor{strings}{rgb}{.824,.251,.259} \definecolor{keywords}{rgb}{.224,.451,.686} \definecolor{comment}{rgb}{.322,.451,.322} \newcommand{\norm}[1]{\left\lVert#1\right\rVert} \newcommand{\coloneqq}{\mathrel{\vcenter{:}}=} \newcommand{\R}{\mathbb{R}} \newcommand{\mathbold}[1]{\boldsymbol{\mathbf{#1}}} \newcommand{\mcK}{\mathcal{K}} \newcommand{\mcN}{\mathcal{N}} \newcommand{\mcO}{\mathcal{O}} \newcommand{\mcP}{\mathcal{P}} \newcommand{\mcC}{\mathcal{C}} \newcommand{\mcS}{\mathcal{S}} \newcommand{\mcL}{\mathcal{L}} \newcommand{\mba}{\mathbold{a}} \newcommand{\mbb}{\mathbold{b}} \newcommand{\mbc}{\mathbold{c}} \newcommand{\mbd}{\mathbold{d}} \newcommand{\mbe}{\mathbold{e}} \newcommand{\vf}{\mathbold{f}} \newcommand{\mbg}{\mathbold{g}} \newcommand{\mbh}{\mathbold{h}} \newcommand{\mbi}{\mathbold{i}} \newcommand{\mbj}{\mathbold{j}} \newcommand{\mbk}{\mathbold{k}} \newcommand{\mbl}{\mathbold{l}} \newcommand{\mbm}{\mathbold{m}} \newcommand{\mbn}{\mathbold{n}} \newcommand{\mbo}{\mathbold{o}} \newcommand{\mbp}{\mathbold{p}} \newcommand{\mbq}{\mathbold{q}} \newcommand{\mbr}{\mathbold{r}} \newcommand{\mbs}{\mathbold{s}} \newcommand{\mbt}{\mathbold{t}} \newcommand{\mbu}{\mathbold{u}} \newcommand{\mbv}{\mathbold{v}} \newcommand{\mbw}{\mathbold{w}} \newcommand{\mbx}{\mathbold{x}} \newcommand{\mby}{\mathbold{y}} \newcommand{\mbz}{\mathbold{z}} \newcommand{\mbA}{\mathbold{A}} \newcommand{\mbB}{\mathbold{B}} \newcommand{\mbC}{\mathbold{C}} \newcommand{\mbD}{\mathbold{D}} \newcommand{\mbE}{\mathbold{E}} \newcommand{\mbF}{\mathbold{F}} \newcommand{\mbG}{\mathbold{G}} \newcommand{\mbH}{\mathbold{H}} \newcommand{\mbI}{\mathbold{I}} \newcommand{\mbJ}{\mathbold{J}} \newcommand{\mbK}{\mathbold{K}} \newcommand{\mbL}{\mathbold{L}} \newcommand{\mbM}{\mathbold{M}} \newcommand{\mbN}{\mathbold{N}} \newcommand{\mbO}{\mathbold{O}} \newcommand{\mbP}{\mathbold{P}} \newcommand{\mbQ}{\mathbold{Q}} \newcommand{\mbR}{\mathbold{R}} \newcommand{\mbS}{\mathbold{S}} \newcommand{\mbT}{\mathbold{T}} \newcommand{\mbU}{\mathbold{U}} \newcommand{\mbV}{\mathbold{V}} \newcommand{\mbW}{\mathbold{W}} \newcommand{\mbX}{\mathbold{X}} \newcommand{\mbY}{\mathbold{Y}} \newcommand{\mbZ}{\mathbold{Z}} \newcommand{\mbphi}{\mathbold{\phi}} \newcommand{\mbtheta}{\mathbold{\theta}} \newcommand{\expandtoken}{[\texttt{EXPAND}]} \newcommand{\deletetoken}{[\texttt{DELETE}]} \newcommand{\masktoken}{[\texttt{MASK}]} \newcommand{\padtoken}{[\texttt{PAD}]} $$ </div> <p><strong>Team:</strong> Zirui Wu*, Lin Zheng*, Zhihui Xie, Jiacheng Ye, Jiahui Gao, Yansong Feng, Zhenguo Li, Victoria W., Guorui Zhou , Lingpeng Kong</p> <p>*: Equal Contribution</p> <p><strong>Affiliations</strong>: The University of Hong Kong, Kuaishou Technology, Huawei Noah‚Äôs Ark Lab, Peking University</p> <h2 id="introducing-dreamon">Introducing DreamOn</h2> <p>In this post, we introduce a simple yet effective training method to unleash the full potential of diffusion language models for variable-length generation. Built upon existing masked diffusion models, our approach features</p> <ul> <li>Flexible generation from any-length sequences</li> <li>Simple and practical implementation with two special sentinel tokens for length control</li> <li>Easy finetuning on existing masked diffusion models</li> <li>Catch up with oracle-length performance on infilling tasks</li> </ul> <p><a href="https://github.com/DreamLM/DreamOn" rel="external nofollow noopener" target="_blank"><strong>üë®‚Äçüíª¬†Github</strong></a> <a href="https://huggingface.co/Dream-org/DreamOn-v0-7B/" rel="external nofollow noopener" target="_blank"><strong>ü§ó¬†HuggingFace</strong></a></p> <h3 id="effective-variable-length-generation-on-infilling">Effective Variable-length Generation on Infilling</h3> <p>Although Diffusion Language Models (DLMs) have recently gained significant attention <d-cite key="austin2021d3pm,hoogeboom2021multinomialdiffusion,zheng2023rdm,lou2024sedd,sahoo2024simplemdm,shi2024md4,nie2025llada,ye2025dream,labs2025mercury"></d-cite>, they face a critical limitation: they require a fixed-size canvas to be specified in advance, making variable-length generation a long-standing and difficult problem. This restriction arises from standard discrete diffusion formulations that merely transmit tokens between different states in-place over a predetermined canvas size.</p> <p>This limitation makes it challenging for DLMs to tackle flexible generation in real-world applications, such as infilling, where the content length must be specified a priori. To illustrate, we evaluate the performance of our <a href="https://hkunlp.github.io/blog/2025/dream-coder/">Dream-Coder-7B</a> on code infilling tasks, where the model is asked to fill the missing span given a prefix and suffix context. When the given mask length does not align with the length of the canonical solution, it struggles to infill the code and pass@1 drops by 35.5% compared with oracle-length performance.</p> <p>In this work, we present <strong>DreamOn</strong> (<u>D</u>iffusion <u>Rea</u>soning <u>M</u>odel with Length C<u>on</u>trol), a novel discrete diffusion algorithm designed to address the variable-length generation challenge in code infilling. Our approach enables <strong>dynamic expansion and contraction of mask tokens</strong> during inference, providing flexible length control without requiring predetermined canvas sizes.</p> <div class="row mt-1"> <div class="col-sm-6 mt-1 mt-md-0"> <figure style="margin-top: 0em"> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dreamcoder-infilling-imgs/code_infilling_dream_from_short.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dreamcoder-infilling-imgs/code_infilling_dream_from_short.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dreamcoder-infilling-imgs/code_infilling_dream_from_short.gif-1400.webp"></source> <img src="/assets/img/dreamcoder-infilling-imgs/code_infilling_dream_from_short.gif" class="img-fluid rounded z-depth-0" width="auto" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture><figcaption class="caption">With too few masked tokens, diffusion models lack sufficient room for meaningful code infilling.</figcaption> </figure> </div> <div class="col-sm-6 mt-1 mt-md-0"> <figure style="margin-top: 0em"> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dreamcoder-infilling-imgs/code_infilling_dream_from_long.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dreamcoder-infilling-imgs/code_infilling_dream_from_long.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dreamcoder-infilling-imgs/code_infilling_dream_from_long.gif-1400.webp"></source> <img src="/assets/img/dreamcoder-infilling-imgs/code_infilling_dream_from_long.gif" class="img-fluid rounded z-depth-0" width="auto" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture><figcaption class="caption">Too many masked tokens cause overgeneration of unnecessary code snippet depth &gt; 0 that is incorrect.</figcaption> </figure> </div> </div> <div class="row mt-1"> <div class="col-sm-6 mt-1 mt-md-0"> <figure style="margin-top: 0em"> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dreamcoder-infilling-imgs/code_infilling_dreaon_from_short.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dreamcoder-infilling-imgs/code_infilling_dreaon_from_short.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dreamcoder-infilling-imgs/code_infilling_dreaon_from_short.gif-1400.webp"></source> <img src="/assets/img/dreamcoder-infilling-imgs/code_infilling_dreaon_from_short.gif" class="img-fluid rounded z-depth-0" width="auto" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture><figcaption class="caption">DreamOn adds mask tokens as needed.</figcaption> </figure> </div> <div class="col-sm-6 mt-1 mt-md-0"> <figure style="margin-top: 0em"> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dreamcoder-infilling-imgs/code_infilling_dreaon_from_long.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dreamcoder-infilling-imgs/code_infilling_dreaon_from_long.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dreamcoder-infilling-imgs/code_infilling_dreaon_from_long.gif-1400.webp"></source> <img src="/assets/img/dreamcoder-infilling-imgs/code_infilling_dreaon_from_long.gif" class="img-fluid rounded z-depth-0" width="auto" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture><figcaption class="caption">DreamOn deletes excess mask tokens.</figcaption> </figure> </div> </div> <p>We believe that enabling variable-length sequence generation opens new avenues for DLMs, unlocking their potential for more sophisticated applications including adaptive prompting, flexible infilling, and seamless editing workflows, particularly in programming contexts where content length is inherently unpredictable.</p> <h3 id="dreamon-masked-diffusion-with-augmented-states">DreamOn: Masked Diffusion with Augmented States</h3> <p>DreamOn extends standard masked diffusion models <d-cite key="austin2021d3pm, hoogeboom2021multinomialdiffusion,zheng2023rdm,lou2024sedd,sahoo2024simplemdm,shi2024md4,ou2025radd,zheng2025masked"></d-cite> by introducing two special states <code class="language-plaintext highlighter-rouge">&lt;|expand|&gt;</code>¬†and¬†<code class="language-plaintext highlighter-rouge">&lt;|delete|&gt;</code> to enable precise length control. We define them in such a way that in the forward diffusion process, ¬†tokens in both <code class="language-plaintext highlighter-rouge">&lt;|expand|&gt;</code>¬†and <code class="language-plaintext highlighter-rouge">&lt;|delete|&gt;</code>¬†are always transmitted to¬†<code class="language-plaintext highlighter-rouge">&lt;|mask|&gt;</code> ; and during the backward process, <code class="language-plaintext highlighter-rouge">&lt;|expand|&gt;</code>¬†is deterministically expanded into two¬†<code class="language-plaintext highlighter-rouge">&lt;|mask|&gt;</code>¬†tokens at the same position, while <code class="language-plaintext highlighter-rouge">&lt;|delete|&gt;</code> is removed from the sequence. This design allows the model to dynamically adjust sequence length.</p> <div class="row mt-1"> <div class="col-sm-12 mt-1 mt-md-0" style="float:none;margin:auto;"> <figure style="margin-top: 0em"> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dreamcoder-infilling-imgs/augmented-diffusion-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dreamcoder-infilling-imgs/augmented-diffusion-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dreamcoder-infilling-imgs/augmented-diffusion-1400.webp"></source> <img src="/assets/img/dreamcoder-infilling-imgs/augmented-diffusion.png" class="img-fluid rounded z-depth-0" width="auto" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture><figcaption class="caption"></figcaption> </figure> </div> </div> <p>To train the model with these special states, we construct an auxiliary sequence¬†$\mbZ_0$ from each original sequence $\mbX_0$¬†by 1) randomly merging token spans in $\mbX_0$¬†into <code class="language-plaintext highlighter-rouge">&lt;|expand|&gt;</code> , and 2) inserting a random number of¬†tokens with state <code class="language-plaintext highlighter-rouge">&lt;|delete|&gt;</code> . As illustrated in the diagram below, $\mbZ_0$ typically differs in length from $\mbX_0$. We then train the masked diffusion model on $\mbZ_0$ instead of diffusing over $\mbX_0$, and by doing so, the model learns to denoise not only regular tokens but also special states from <code class="language-plaintext highlighter-rouge">&lt;|mask|&gt;</code>, thus achieving effective variable-length generation.</p> <h3 id="implementation">Implementation</h3> <p>Similar to <code class="language-plaintext highlighter-rouge">&lt;|mask|&gt;</code> in masked diffusion models, we define the introduced states <code class="language-plaintext highlighter-rouge">&lt;|expand|&gt;</code>¬†and¬†<code class="language-plaintext highlighter-rouge">&lt;|delete|&gt;</code> as special sentinel tokens in the tokenizer vocabulary, and train the model to denoise them just as if they were regular tokens. This formulation is appealing due to its ease of implementation ‚Äî requiring no changes to the model architecture and supporting straightforward fine-tuning from pretrained masked diffusion models.</p> <h4 id="training">Training</h4> <p>To construct $\mbZ_0$, instead of merging and inserting tokens before masking (as demonstrated in the diagram above), we first apply a mask noising process over¬†$\mbX_0$, followed by random merges of consecutive¬†<code class="language-plaintext highlighter-rouge">&lt;|mask|&gt;</code>¬†tokens to form¬†<code class="language-plaintext highlighter-rouge">&lt;|expand|&gt;</code>¬†and random insertion of¬†<code class="language-plaintext highlighter-rouge">&lt;|delete|&gt;</code>¬†tokens. This sampling scheme provides greater control over the noise level and the balance between length control and generation quality (see Section Analysis).</p> <p>We design two heuristic schedulers for constructing¬†<code class="language-plaintext highlighter-rouge">&lt;|expand|&gt;</code>¬†tokens. (1) <strong>Static scheduler</strong> merges adjacency¬†<code class="language-plaintext highlighter-rouge">&lt;|mask|&gt;</code>¬†tokens with a fixed merging probability $p_{merge}=0.5$. (2) <strong>Dynamic inverse scheduler</strong> merges adjacent¬†<code class="language-plaintext highlighter-rouge">&lt;|mask|&gt;</code>¬†with a probability that is inversely proportional to the number of¬†<code class="language-plaintext highlighter-rouge">&lt;|mask|&gt;</code>¬†tokens in the sequence. We find that mixing the two schedulers leads to the best performance in practice.</p> <p>We fine-tune <a href="https://hkunlp.github.io/blog/2025/dream-coder/"><code class="language-plaintext highlighter-rouge">DreamCoder-7B</code></a> on the education instruct subset of <a href="https://huggingface.co/datasets/OpenCoder-LLM/opc-sft-stage2" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">opc-sft-stage2</code></a> from <a href="https://arxiv.org/pdf/2411.04905" rel="external nofollow noopener" target="_blank">OpenCoder</a>. This subset contains 110k instruction-solution pairs synthesized from seed data of high educational value. For infilling tasks, we randomly split the solution into prefix, middle, and suffix. We treat the instruction, prefix, and suffix of the solution as fixed, and only diffuse over tokens in the middle. In this case, we found it suffices to learn effective sequence contraction by appending a random number of <code class="language-plaintext highlighter-rouge">&lt;|delete|&gt;</code> tokens at the end of the middle section. We downweight the loss of predicting¬†<code class="language-plaintext highlighter-rouge">&lt;|delete|&gt;</code>¬†tokens to avoid overfitting.</p> <h4 id="inference">Inference</h4> <p>During inference, our model shows little difference from the original masked diffusion denoising, except that at each iteration, when a¬†<code class="language-plaintext highlighter-rouge">&lt;|expand|&gt;</code>¬†token is predicted from¬†<code class="language-plaintext highlighter-rouge">&lt;|mask|&gt;</code> , we expand it into two¬†<code class="language-plaintext highlighter-rouge">&lt;|mask|&gt;</code>¬†tokens in the same position; and when a¬†<code class="language-plaintext highlighter-rouge">&lt;|delete|&gt;</code>¬†token is predicted, we simply remove it from the sequence. This is a crude heuristic that greedily expands or contracts sequence length at each step; however, we found it performed effectively and robustly in infilling tasks.</p> <h3 id="evaluation">Evaluation</h3> <p>We evaluate our model on HumanEval-Infilling and the Python subset of Santacoder-FIM. We report pass@1 for HumanEval-Infilling and exact match for Santacoder-FIM following official evaluation scripts. We evaluate our model with different initial mask lengths to assess its generalizability in length control. We also evaluate the performance under oracle length, with expansion and deletion disabled for this setting, to monitor the infilling capabilities for fixed-size canvas.</p> <style>figure+.caption,figure .caption{text-align:left!important}</style> <div class="row mt-1"> <div class="col-sm-12 col-md-8 col-lg-6" style="float:none;margin:auto;"> <figure style="margin-top: 0em"> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dreamcoder-infilling-imgs/main_result-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dreamcoder-infilling-imgs/main_result-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dreamcoder-infilling-imgs/main_result-1400.webp"></source> <img src="/assets/img/dreamcoder-infilling-imgs/main_result.png" class="img-fluid rounded z-depth-0" width="auto" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture><figcaption class="caption">Pass@1 on HumanEval-Infilling and exact match on Santacoder-FIM. We evaluate the infilling performance of diffusion language models by averaging results across given mask lengths of 4, 8, 16, 32, and 64.</figcaption> </figure> </div> </div> <p>Our results demonstrate that DreamOn achieves significant improvements over other diffusion models that lack variable-length generation capabilities in code infilling, approaching the performance of leading open-source autoregressive language models that are trained with infilling objectives.</p> <h3 id="analysis">Analysis</h3> <h4 id="performance-breakdown">Performance Breakdown</h4> <p>We perform ablation studies on our expansion and contraction design to show the effectiveness of our approach. Performance with different masked token lengths shows that DLMs trained on infilling without sentinel tokens exhibit poor performance, particularly on short sequences, while those incorporating both expansion and deletion achieve the highest pass@1 across all lengths. The combination of both mechanisms leads to a substantial improvement in pass rate (90.8% average) and exact match accuracy (73.9% average), approaching oracle performance.</p> <div class="row mt-1"> <div class="col-sm-10 mt-1 mt-md-0" style="float:none;margin:auto;"> <figure style="margin-top: 0em"> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dreamcoder-infilling-imgs/breakdown-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dreamcoder-infilling-imgs/breakdown-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dreamcoder-infilling-imgs/breakdown-1400.webp"></source> <img src="/assets/img/dreamcoder-infilling-imgs/breakdown.png" class="img-fluid rounded z-depth-0" width="auto" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture><figcaption class="caption">Pass@1 and exact for diffusion language model with different mask length. w/o Delete or Expand : deletion or expansion excluded from training. Oracle: performance under oracle length without expansion or deletion as reference. ‚Ä†: We use an AST parser to compute exact match to normalize huge syntactic differences between the model output and the ground truth.</figcaption> </figure> </div> </div> <p>Exact match scores highlight that our approach leads to perfect token alignment with the ground truth regardless of the length of the infilling span. Our approach offers a text diffusion process that is no longer limited to fixed-length sequences and can adapt to variable-length generation tasks at scale, such as infilling.</p> <h4 id="padding-vs-deletion">Padding vs. Deletion</h4> <p>Current DLMs often use <code class="language-plaintext highlighter-rouge">&lt;|pad|&gt;</code> tokens to fill at the end of the sequence, which can be viewed as a special form of length cutoff control. The predicted <code class="language-plaintext highlighter-rouge">&lt;|pad|&gt;</code> tokens are kept in the sequence as input for the next step of denoising. We experiment with training our model while keeping <code class="language-plaintext highlighter-rouge">&lt;|delete|&gt;</code> tokens in the prompt and do not remove them from the sequence. The presence of <code class="language-plaintext highlighter-rouge">&lt;|delete|&gt;</code> tokens introduces potential distraction into the denoising process, which could disrupt attention patterns or token-position alignments, especially when deletions are frequent or irregular. Our design of <code class="language-plaintext highlighter-rouge">&lt;|delete|&gt;</code> tokens offers greater flexibility and effectiveness for dynamic length control</p> <div class="row mt-1"> <div class="col-sm-10 mt-1 mt-md-0" style="float:none;margin:auto;"> <figure style="margin-top: 0em"> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dreamcoder-infilling-imgs/ablation-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dreamcoder-infilling-imgs/ablation-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dreamcoder-infilling-imgs/ablation-1400.webp"></source> <img src="/assets/img/dreamcoder-infilling-imgs/ablation.png" class="img-fluid rounded z-depth-0" width="auto" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture><figcaption class="caption">Ablation study for length shortening strategy and merging scheduler for mask expansion. Oracle: performance under oracle length without expansion or deletion as reference.</figcaption> </figure> </div> </div> <h4 id="choice-of-merging-scheduler">Choice of Merging Scheduler</h4> <p>Balancing between the degree of length control and the quality of generation is crucial for robust variable-length generation. We train our model with static or dynamic inverse scheduler separately to study their effect on generalizability.</p> <p>The static scheduler offers a higher degree of length control, achieving the highest pass rate when the mask length is extremely short. However, it leads to lower quality generation compared with other schedulers. Large number of regular tokens that are replaced with <code class="language-plaintext highlighter-rouge">&lt;|expand|&gt;</code> tokens during training and have negative effects on language modeling abilities. The dynamic inverse scheduler addresses this problem by downweighting merged <code class="language-plaintext highlighter-rouge">&lt;|expand|&gt;</code> tokens. But it has poor expanding performance when the mask length is too short. Therefore, we mix the two schedulers to balance length control and quality of generation.</p> <h3 id="conclusion">Conclusion</h3> <p>It remains challenging for non-autoregressive generative models to generate variable-length sequences. Prior research has explored several strategies to address this, such as learning a separate length prediction module <d-cite key="gu2018narmt, lee2018deterministic,ghazvininejad2019cmlm,zheng2023rdm"></d-cite>, contracting length with latent alignment marginalization <d-cite key="chan2020imputer"></d-cite>, incorporating edit operations <d-cite key="gu2019insertion,gu2019levenshtein,stern2019insertion,johnson2021beyond,reid2023diffuser,campbell2023transdimensional,patel2025insertionlm,havasi2025editflow"></d-cite>, and performing diffusion over sequence positions <d-cite key="zhang2025flexible"></d-cite>. Most of these methods require modifying the model architecture and have been evaluated at limited scale.</p> <p>In contrast, our approach introduces only two special tokens into the tokenizer vocabulary‚Äîrequiring no changes to the model architecture or the loss objective. This leads to a simple and scalable implementation that remains effective on infilling tasks. Notably, DreamOn even achieves code infilling performance comparable to that with oracle length, highlighting its capability to handle variable-length generation.</p> <p>This blog post presents our preliminary results on variable-length generation with DLMs. Future work will explore extensions beyond fill-in-the-middle (FIM) tasks and further improve training and inference strategies.</p> <h3 id="citation">Citation</h3> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@misc</span><span class="p">{</span><span class="nl">Dreamon2025</span><span class="p">,</span>
    <span class="na">title</span> <span class="p">=</span> <span class="s">{DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas}</span><span class="p">,</span>
    <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hkunlp.github.io/blog/2025/dreamon}</span><span class="p">,</span>
    <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu, Zirui and Zheng, Lin and Xie, Zhihui and Ye, Jiacheng and Gao, Jiahui and Feng, Yansong and Li, Zhenguo and W., Victoria and Zhou, Guorui  and Kong, Lingpeng}</span>
    <span class="nv">year</span> <span class="err">=</span> <span class="err">{2025</span><span class="p">}</span>
<span class="c">}</span>
</code></pre></div></div> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2025 HKU NLP Group . Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <d-bibliography src="/assets/bibliography/2025-07-15-dreamon.bib"></d-bibliography> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>